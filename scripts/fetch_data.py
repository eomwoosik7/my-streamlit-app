import yfinance as yf
import pandas as pd
import os
import requests
from bs4 import BeautifulSoup
import FinanceDataReader as fdr
from datetime import datetime, timedelta
from multiprocessing import Pool
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import json
import time
import shutil
import numpy as np

DATA_DIR = os.getenv('DATA_DIR', './data')
os.makedirs(DATA_DIR, exist_ok=True)

META_DIR = os.path.join(DATA_DIR, 'meta')
DB_PATH = os.path.join(META_DIR, 'universe.db')
RESULTS_PATH = os.path.join(META_DIR, 'backtest.db')

if os.path.exists(DB_PATH):
    os.remove(DB_PATH)
    print("universe.db ì‚­ì œ ì™„ë£Œ!")

if os.path.exists(RESULTS_PATH):
    os.remove(RESULTS_PATH)
    print("screener_results.parquet ì‚­ì œ ì™„ë£Œ!")

# âœ… ì˜¤ëŠ˜ ë‚ ì§œë¥¼ í‰ì¼ë¡œ ì¡°ì •
today = datetime.now()
if today.weekday() == 5:  # í† ìš”ì¼
    today -= timedelta(days=1)
    print(f"âš ï¸ í† ìš”ì¼ â†’ ê¸ˆìš”ì¼ë¡œ ì¡°ì •: {today.strftime('%Y-%m-%d')}")
elif today.weekday() == 6:  # ì¼ìš”ì¼
    today -= timedelta(days=2)
    print(f"âš ï¸ ì¼ìš”ì¼ â†’ ê¸ˆìš”ì¼ë¡œ ì¡°ì •: {today.strftime('%Y-%m-%d')}")

def get_kr_tickers():
    """FinanceDataReaderë¡œ KRX ìƒì¥ ì¢…ëª© ì¡°íšŒ"""
    try:
        print("ğŸ“Š KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì¤‘...")
        
        # âœ… KRX ì „ì²´ ì¢…ëª© (KOSPI + KOSDAQ + KONEX)
        df_krx = fdr.StockListing('KRX')
        
        if df_krx.empty:
            print("ğŸš¨ KRX ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
            return [], pd.DataFrame(), None
        
        # âœ… ë””ë²„ê¹…: ì»¬ëŸ¼ëª… í™•ì¸
        print(f"ğŸ“‹ ì‹¤ì œ ì»¬ëŸ¼ëª…: {df_krx.columns.tolist()}")
        print(f"ğŸ“Š ìƒ˜í”Œ ë°ì´í„°:\n{df_krx.head(3)}")
        
        # âœ… ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ëª… ì°¾ê¸° (ì—¬ëŸ¬ ê°€ëŠ¥ì„± í™•ì¸)
        cap_col = None
        possible_names = ['MarketCap', 'Market Cap', 'Marcap', 'ì‹œê°€ì´ì•¡', 'CapSize']
        
        for col_name in possible_names:
            if col_name in df_krx.columns:
                cap_col = col_name
                print(f"âœ… ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ë°œê²¬: {cap_col}")
                break
        
        if cap_col is None:
            print("âš ï¸ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì—†ìŒ - Stocks(ìŠ¤í†¡ìŠ¤) ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬ ì‹œë„")
            # ì‹œê°€ì´ì•¡ì´ ì—†ìœ¼ë©´ ì¢…ëª©ì½”ë“œ ìˆœìœ¼ë¡œ ìƒìœ„ 1000ê°œ
            df_kr = df_krx.head(1000)
        else:
            # ì‹œê°€ì´ì•¡ ì •ë¦¬
            df_krx[cap_col] = pd.to_numeric(df_krx[cap_col], errors='coerce').fillna(0)
            # ìƒìœ„ 1000ê°œ ì¢…ëª©
            df_kr = df_krx.sort_values(cap_col, ascending=False).head(1000)
        
        kr_tickers = df_kr['Code'].tolist()
        date_str = today.strftime('%Y%m%d')
        
        print(f"âœ… KR ìƒìœ„ 1000: {len(kr_tickers)}ê°œ (ë‚ ì§œ: {date_str})")
        print(f"ìƒ˜í”Œ: {kr_tickers[:5]}")
        
        return kr_tickers, df_kr, date_str
        
    except Exception as e:
        print(f"âŒ KRX ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return [], pd.DataFrame(), None

def get_us_symbols():
    """US Russell 1000 ì¢…ëª© ì¡°íšŒ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
    url = 'https://en.wikipedia.org/wiki/Russell_1000_Index'
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        tables = soup.find_all('table')
        
        for table in tables:
            if 'Symbol' in str(table):
                df_us = pd.read_html(str(table))[0]
                us_symbols = df_us['Symbol'].str.replace('.', '-', regex=False).tolist()
                print(f"âœ… US ìƒìœ„ {len(us_symbols)}ê°œ ë¡œë“œ (Russell 1000)")
                return us_symbols, df_us
        
        print("âŒ US í…Œì´ë¸” ì°¾ê¸° ì‹¤íŒ¨")
        return [], pd.DataFrame()
    except Exception as e:
        print(f"âŒ US ì‹¬ë³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return [], pd.DataFrame()

def fetch_us_single(symbol, start_date):
    """US ì¼ë´‰ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
    try:
        ticker = yf.Ticker(symbol)
        data = ticker.history(start=start_date, end=today, interval="1d")
        if data.empty:
            return
        daily_dir = os.path.join(DATA_DIR, 'us_daily')
        os.makedirs(daily_dir, exist_ok=True)
        data.to_csv(os.path.join(daily_dir, f"{symbol}.csv"), encoding='utf-8-sig')
    except Exception as e:
        print(f"âŒ {symbol} ì˜¤ë¥˜: {e}")

def fetch_kr_single(ticker, start_date):
    """âœ… FinanceDataReaderë¡œ KR ì¼ë´‰ ë‹¤ìš´ë¡œë“œ"""
    try:
        # âœ… FDRì€ datetime ê°ì²´ ì‚¬ìš©
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        
        # âœ… DataReaderë¡œ ì¼ë´‰ ì¡°íšŒ
        data = fdr.DataReader(ticker, start=start_dt, end=today)
        
        if data.empty:
            print(f"âš ï¸ {ticker} ë°ì´í„° ì—†ìŒ")
            return
        
        # ì»¬ëŸ¼ëª…ì„ ì˜ë¬¸ìœ¼ë¡œ í†µì¼ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜)
        data = data.rename(columns={
            'ì‹œê°€': 'Open',
            'ê³ ê°€': 'High', 
            'ì €ê°€': 'Low',
            'ì¢…ê°€': 'Close',
            'ê±°ë˜ëŸ‰': 'Volume'
        })
        
        # Open, High, Low, Close, Volumeë§Œ ì €ì¥
        data = data[['Open', 'High', 'Low', 'Close', 'Volume']]
        
        daily_dir = os.path.join(DATA_DIR, 'kr_daily')
        os.makedirs(daily_dir, exist_ok=True)
        data.to_csv(os.path.join(daily_dir, f"{ticker}.csv"), encoding='utf-8-sig')
        
    except Exception as e:
        print(f"âŒ {ticker} ì˜¤ë¥˜: {e}")

def get_kr_meta_single(ticker, df_kr):
    """âœ… KR ë©”íƒ€ ì •ë³´ ì¶”ì¶œ (FinanceDataReader ê¸°ë°˜)"""
    cap = 0.0
    name = "N/A"
    per = 0.0  # âš ï¸ FDRì€ PER/EPS ë¯¸ì œê³µ â†’ 0ìœ¼ë¡œ ì„¤ì •
    eps = 0.0
    close_price = 0.0
    cap_status = "N/A"
    
    try:
        # df_krì—ì„œ ì¢…ëª© ì •ë³´ ì¶”ì¶œ
        if ticker in df_kr['Code'].values:
            row = df_kr[df_kr['Code'] == ticker].iloc[0]
            
            name = row.get('Name', 'N/A')
            
            # âœ… ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ëª… ë™ì  íƒìƒ‰
            cap_col = None
            for col_name in ['MarketCap', 'Market Cap', 'Marcap', 'ì‹œê°€ì´ì•¡', 'CapSize']:
                if col_name in df_kr.columns:
                    cap_col = col_name
                    break
            
            if cap_col:
                cap = float(row.get(cap_col, 0))
            
            if cap > 0:
                cap_status = today.strftime('%Y-%m-%d')
            
            # âœ… ì¢…ê°€ëŠ” df_krì˜ Close ì»¬ëŸ¼ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (API ì¬í˜¸ì¶œ ë¶ˆí•„ìš”!)
            if 'Close' in df_kr.columns:
                close_price = float(row.get('Close', 0))
                
    except Exception as e:
        print(f"âš ï¸ {ticker} ë©”íƒ€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    return ticker, cap, name, per, eps, close_price, cap_status

def get_us_meta_single(symbol, df_us):
    """US ë©”íƒ€ ì •ë³´ ì¶”ì¶œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
    cap = 0.0
    name = "N/A"
    per = 0.0
    eps = 0.0
    close_price = 0.0
    sector = "N/A"
    try:
        ticker = yf.Ticker(symbol)
        info = ticker.info
        name = info.get('longName') or info.get('shortName') or "N/A"
        per = round(info.get('trailingPE') or info.get('forwardPE') or 0.0, 2)
        eps = round(info.get('trailingEps') or info.get('forwardEps') or 0.0, 2)

        shares = info.get('sharesOutstanding')
        if shares and shares > 0:
            hist = ticker.history(start=today - timedelta(days=5), end=today)
            if not hist.empty:
                cap = shares * hist['Close'].iloc[-1]
                close_price = hist['Close'].iloc[-1]
        
        symbol_dot = symbol.replace('-', '.')
        if 'Symbol' in df_us.columns and 'GICS Sector' in df_us.columns:
            matching = df_us[df_us['Symbol'] == symbol_dot]
            if not matching.empty:
                sector = matching['GICS Sector'].iloc[0]
    except:
        pass
    return symbol, float(cap), name, per, eps, float(close_price), sector

if __name__ == '__main__':
    print(f"ğŸ—“ï¸ ì‘ì—… ê¸°ì¤€ì¼: {today.strftime('%Y-%m-%d %A')}")
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    for folder in ['kr_daily', 'us_daily']:
        path = os.path.join(DATA_DIR, folder)
        if os.path.exists(path):
            shutil.rmtree(path)
            print(f"ğŸ—‘ï¸ {folder} í´ë” ì‚­ì œ ì™„ë£Œ")
        os.makedirs(path, exist_ok=True)
    
    # ë©”íƒ€ íŒŒì¼ ë¡œë“œ
    meta_dir = os.path.join(DATA_DIR, 'meta')
    os.makedirs(meta_dir, exist_ok=True)
    meta_file = os.path.join(meta_dir, 'tickers_meta.json')
    
    if os.path.exists(meta_file):
        with open(meta_file, 'r', encoding='utf-8') as f:
            old_meta = json.load(f)
        print("ğŸ“‚ ê¸°ì¡´ meta.json ë¡œë“œ ì™„ë£Œ")
    else:
        old_meta = {'KR': {}, 'US': {}}
        print("ğŸ“ ê¸°ì¡´ meta.json ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„±")
    
    start_date = (today - timedelta(days=730)).strftime('%Y-%m-%d')
    
    # âœ… KR ë°ì´í„° ìˆ˜ì§‘
    print("\n" + "="*50)
    print("ğŸ‡°ğŸ‡· KR ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print("="*50)
    kr_tickers, df_kr, kr_date_str = get_kr_tickers()
    
    # âœ… US ë°ì´í„° ìˆ˜ì§‘
    print("\n" + "="*50)
    print("ğŸ‡ºğŸ‡¸ US ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print("="*50)
    us_symbols, df_us = get_us_symbols()

    # US ì¼ë´‰ ë‹¤ìš´ë¡œë“œ
    if us_symbols:
        print("\nğŸ“¥ US ì¼ë´‰ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        with Pool(4) as pool:
            pool.starmap(fetch_us_single, [(s, start_date) for s in us_symbols])

    # KR ì¼ë´‰ ë‹¤ìš´ë¡œë“œ
    if kr_tickers:
        print("\nğŸ“¥ KR ì¼ë´‰ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        for i in range(0, len(kr_tickers), 100):
            batch = kr_tickers[i:i+100]
            with Pool(4) as pool:
                pool.starmap(fetch_kr_single, [(t, start_date) for t in batch])
            print(f"ì§„í–‰: {min(i+100, len(kr_tickers))}/{len(kr_tickers)}")
            time.sleep(2)  # API ë¶€í•˜ ë°©ì§€
    
    # KR ë©”íƒ€ ì—…ë°ì´íŠ¸
    kr_meta = old_meta.get('KR', {})
    if kr_tickers and not df_kr.empty:
        print("\nğŸ“Š KR ë©”íƒ€ ìˆ˜ì§‘ ì‹œì‘")
        print("âš ï¸ ì£¼ì˜: PER/EPSëŠ” FinanceDataReaderì—ì„œ ì œê³µí•˜ì§€ ì•Šì•„ 0ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤")
        
        batch_size = 200
        for i in tqdm(range(0, len(kr_tickers), batch_size)):
            batch_tickers = kr_tickers[i:i+batch_size]
            with ThreadPoolExecutor(max_workers=5) as executor:
                results = executor.map(
                    lambda t: get_kr_meta_single(t, df_kr), 
                    batch_tickers
                )
            for ticker, cap, name, per, eps, close_price, cap_status in results:
                old_data = kr_meta.get(ticker, {})
                kr_meta[ticker] = {
                    'name': name if name != "N/A" else old_data.get('name', "N/A"),
                    'cap': cap if cap > 0 else old_data.get('cap', 0.0),
                    'cap_status': cap_status if cap > 0 else old_data.get('cap_status', "N/A"),
                    'per': per,  # âš ï¸ FDRì€ 0
                    'eps': eps,  # âš ï¸ FDRì€ 0
                    'close': close_price if close_price > 0 else old_data.get('close', 0.0)
                }
            time.sleep(5)  # API ë¶€í•˜ ë°©ì§€

    # US ë©”íƒ€ ì—…ë°ì´íŠ¸
    us_meta = old_meta.get('US', {})
    us_cap_date = today.strftime('%Y-%m-%d')
    if us_symbols:
        print("\nğŸ“Š US ë©”íƒ€ ìˆ˜ì§‘ ì‹œì‘")
        batch_size = 200
        for i in tqdm(range(0, len(us_symbols), batch_size)):
            batch_symbols = us_symbols[i:i+batch_size]
            with ThreadPoolExecutor(max_workers=5) as executor:
                results = executor.map(lambda s: get_us_meta_single(s, df_us), batch_symbols)
            for symbol, new_cap, name, per, eps, close_price, sector in results:
                old_data = us_meta.get(symbol, {})
                us_meta[symbol] = {
                    'name': name if name != "N/A" else old_data.get('name', "N/A"),
                    'cap': new_cap if new_cap > 0 else old_data.get('cap', 0.0),
                    'cap_status': us_cap_date if new_cap > 0 else old_data.get('cap_status', "N/A"),
                    'per': per if per != 0.0 else old_data.get('per', 0.0),
                    'eps': eps if eps != 0.0 else old_data.get('eps', 0.0),
                    'close': close_price if close_price > 0 else old_data.get('close', 0.0),
                    'sector': sector if sector != "N/A" else old_data.get('sector', "N/A")
                }
            time.sleep(30)

    # JSON ì €ì¥
    def convert_np(obj):
        if isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, dict):
            return {k: convert_np(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [convert_np(i) for i in obj]
        return obj

    kr_meta = convert_np(kr_meta)
    us_meta = convert_np(us_meta)

    with open(meta_file, 'w', encoding='utf-8') as f:
        json.dump({'KR': kr_meta, 'US': us_meta}, f, ensure_ascii=False, indent=2)

    print("\n" + "="*50)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {meta_file}")
    print(f"ğŸ“Š KR: {len(kr_meta)}ê°œ | US: {len(us_meta)}ê°œ")
    print("="*50)
    print("\nâš ï¸ ì¤‘ìš” ì•Œë¦¼:")
    print("1. PER/EPSëŠ” FinanceDataReaderì—ì„œ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
    print("2. ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ë°ì´í„°ë„ ìˆ˜ì§‘ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤")
    print("3. ì„¹í„° ì •ë³´ëŠ” ë³„ë„ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")