import duckdb
import pandas as pd
import os
import json
import numpy as np
from pykrx import stock
import yfinance as yf
import sys
from datetime import datetime, timedelta
import time
import traceback

DATA_DIR = os.getenv('DATA_DIR', './data')
os.makedirs(DATA_DIR, exist_ok=True)
META_DIR = os.path.join(DATA_DIR, 'meta')
os.makedirs(META_DIR, exist_ok=True)
DB_PATH = os.path.join(META_DIR, 'universe.db')
BACKTEST_DB_PATH = os.path.join(META_DIR, 'backtest.db')
BACKTEST_CSV_PATH = os.path.join(DATA_DIR, 'backtest_results.csv')

# âœ… í…ŒìŠ¤íŠ¸ íƒ­ìš© CSV ê²½ë¡œ ì¶”ê°€
BACKTEST_TEST_CSV_PATH = os.path.join(DATA_DIR, 'backtest_test.csv')

SHORT_FOLDER = os.path.join(DATA_DIR, 'short_term_results')
MID_FOLDER = os.path.join(DATA_DIR, 'screener_results')
SELL_FOLDER = os.path.join(DATA_DIR, 'sell_signals')
os.makedirs(SHORT_FOLDER, exist_ok=True)
os.makedirs(MID_FOLDER, exist_ok=True)
os.makedirs(SELL_FOLDER, exist_ok=True)

META_FILE = os.path.join(META_DIR, 'tickers_meta.json')

def load_meta():
    if os.path.exists(META_FILE):
        with open(META_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        print("ë©”íƒ€ íŒŒì¼ ì—†ìŒ â€“ ë¹ˆ ë”•íŠ¸ ë°˜í™˜")
        return {'KR': {}, 'US': {}}

def add_close_price(df):
    if df.empty or 'symbol' not in df.columns or 'market' not in df.columns:
        return df
    meta = load_meta()
    df = df.copy()
    df['close'] = np.nan
    for idx, row in df.iterrows():
        symbol = row['symbol']
        market = row['market']
        meta_dict = meta.get(market, {}).get(symbol, {})
        close_price = meta_dict.get('close', 0.0)
        df.at[idx, 'close'] = close_price
    return df

def get_historical_close(symbol, market, target_date):
    """CSV íŒŒì¼ì—ì„œ íŠ¹ì • ë‚ ì§œì˜ ì¢…ê°€ ì¡°íšŒ"""
    try:
        if market == 'KR':
            daily_path = os.path.join(DATA_DIR, 'kr_daily', f"{symbol}.csv")
        else:
            daily_path = os.path.join(DATA_DIR, 'us_daily', f"{symbol}.csv")
        
        if not os.path.exists(daily_path):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {symbol} ({market})")
            return None
        
        df = pd.read_csv(daily_path, index_col=0, parse_dates=True)
        
        if market == 'KR':
            df = df.rename(columns={
                'ì‹œê°€': 'Open', 'ê³ ê°€': 'High', 'ì €ê°€': 'Low',
                'ì¢…ê°€': 'Close', 'ê±°ë˜ëŸ‰': 'Volume'
            })
        
        target_str = target_date.strftime('%Y-%m-%d')
        df.index = pd.to_datetime(df.index).strftime('%Y-%m-%d')
        
        if target_str in df.index:
            close_price = df.loc[target_str, 'Close']
            return float(close_price)
        
        valid_dates = [d for d in df.index if d <= target_str]
        if valid_dates:
            closest_date = valid_dates[-1]
            close_price = df.loc[closest_date, 'Close']
            print(f"â„¹ï¸ {symbol} ëª©í‘œì¼ {target_str} â†’ ì´ì „ ì˜ì—…ì¼ {closest_date} ì‚¬ìš©")
            return float(close_price)
        
        print(f"âš ï¸ {symbol} ëª©í‘œì¼ {target_str} ì´ì „ ë°ì´í„° ì—†ìŒ")
        return None
    
    except Exception as e:
        print(f"âš ï¸ ì¢…ê°€ ì¡°íšŒ ì‹¤íŒ¨: {symbol} ({market}) - {target_date.strftime('%Y-%m-%d')} - {e}")
        return None

def get_closes_in_range(symbol, market, base_date, target_date):
    """
    ê¸°ì¤€ì¼(base_date) ë‹¤ìŒë‚ ë¶€í„° ëª©í‘œì¼(target_date)ê¹Œì§€ì˜
    ë‚ ì§œë³„ ì¢…ê°€ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜
    ë°˜í™˜: DataFrame with columns ['date', 'close'] (ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ)
    """
    try:
        if market == 'KR':
            daily_path = os.path.join(DATA_DIR, 'kr_daily', f"{symbol}.csv")
        else:
            daily_path = os.path.join(DATA_DIR, 'us_daily', f"{symbol}.csv")

        if not os.path.exists(daily_path):
            return pd.DataFrame(columns=['date', 'close'])

        df = pd.read_csv(daily_path, index_col=0, parse_dates=True)

        if market == 'KR':
            df = df.rename(columns={
                'ì‹œê°€': 'Open', 'ê³ ê°€': 'High', 'ì €ê°€': 'Low',
                'ì¢…ê°€': 'Close', 'ê±°ë˜ëŸ‰': 'Volume'
            })

        df.index = pd.to_datetime(df.index)
        df = df.sort_index()

        # ê¸°ì¤€ì¼ ë‹¤ìŒë‚  ~ ëª©í‘œì¼ ë²”ìœ„ í•„í„°
        base_str = base_date.strftime('%Y-%m-%d')
        target_str = target_date.strftime('%Y-%m-%d')
        df_range = df[(df.index > base_str) & (df.index <= target_str)][['Close']].copy()
        df_range = df_range.reset_index()
        df_range.columns = ['date', 'close']
        df_range['date'] = df_range['date'].dt.strftime('%Y-%m-%d')

        return df_range

    except Exception as e:
        print(f"âš ï¸ êµ¬ê°„ ì¢…ê°€ ì¡°íšŒ ì‹¤íŒ¨: {symbol} ({market}) - {e}")
        return pd.DataFrame(columns=['date', 'close'])

con = None

def ensure_db_exists():
    if not os.path.exists(DB_PATH):
        con_temp = duckdb.connect(DB_PATH, read_only=False)
        con_temp.execute("""
            CREATE TABLE IF NOT EXISTS indicators (
                symbol VARCHAR PRIMARY KEY,
                market VARCHAR,
                name VARCHAR,
                rsi_d TEXT,
                macd_d TEXT,
                signal_d TEXT,
                obv_d TEXT,
                signal_obv_9d TEXT,
                signal_obv_20d TEXT,
                market_cap DOUBLE,
                avg_trading_value_20d DOUBLE,
                today_trading_value DOUBLE,
                turnover DOUBLE,
                per DOUBLE,
                eps DOUBLE,
                cap_status VARCHAR,
                upper_closes INTEGER,
                lower_closes INTEGER,
                sector VARCHAR,
                sector_trend VARCHAR,
                ma20 TEXT,
                ma50 TEXT,
                ma200 TEXT,
                break_20high INTEGER,
                close_d TEXT
            )
        """)
        con_temp.close()
        print(f"DB ìƒì„± ì™„ë£Œ: {DB_PATH}")

try:
    ensure_db_exists()
    con = duckdb.connect(DB_PATH)
    print("DB ì—°ê²° ì„±ê³µ!")
except duckdb.IOException:
    print("DB íŒŒì¼ ì ê¹€ â€“ 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
    time.sleep(5)
    ensure_db_exists()
    con = duckdb.connect(DB_PATH)

def run_screener(top_n=50, use_us=True, use_kr=True):
    try:
        print("ìŠ¤í¬ë¦¬ë„ˆ ì‹œì‘...")
        row_count = con.execute("SELECT COUNT(*) FROM indicators").fetchone()[0]
        print(f"DB í–‰ ìˆ˜: {row_count}")
        
        if row_count == 0:
            print("âŒ DBê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! compute_indicators.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return pd.DataFrame()
        
        df = con.execute("SELECT * FROM indicators").fetchdf()
        print(f"ì „ì²´ ë°ì´í„° ë¡œë“œ: {len(df)}í–‰")

        # JSON íŒŒì‹±
        def parse_json_array(col, num_vals=3):
            def safe_parse(x):
                if pd.isna(x) or not isinstance(x, str) or len(x) <= 2:
                    return [0.0] * num_vals
                try:
                    arr = json.loads(x)
                    return [float(v) if isinstance(v, (int, float)) else 0.0 for v in arr[:num_vals]]
                except:
                    return [0.0] * num_vals
            parsed = df[col].apply(safe_parse).apply(pd.Series)
            return parsed.iloc[:, :num_vals]

        # RSI íŒŒì‹±
        rsi_parsed = parse_json_array('rsi_d', 3)
        df['rsi_d_2ago'] = rsi_parsed[0]
        df['rsi_d_1ago'] = rsi_parsed[1]
        df['rsi_d_latest'] = rsi_parsed[2]

        # OBV íŒŒì‹±
        obv_parsed = parse_json_array('obv_d', 3)
        df['obv_latest'] = obv_parsed[0]
        df['obv_1ago'] = obv_parsed[1]
        df['obv_2ago'] = obv_parsed[2]

        # OBV 9ì¼ í‰ê·  íŒŒì‹±
        signal_obv_9_parsed = parse_json_array('signal_obv_9d', 3)
        df['signal_obv_9_latest'] = signal_obv_9_parsed[0]
        df['signal_obv_9_1ago'] = signal_obv_9_parsed[1]

        # OBV 20ì¼ í‰ê·  íŒŒì‹± (4ì¼ì¹˜)
        signal_obv_20_parsed = parse_json_array('signal_obv_20d', 4)
        df['signal_obv_20_latest'] = signal_obv_20_parsed[0]
        df['signal_obv_20_1ago'] = signal_obv_20_parsed[1]
        df['signal_obv_20_2ago'] = signal_obv_20_parsed[2]
        df['signal_obv_20_3ago'] = signal_obv_20_parsed[3]

        # ì¢…ê°€ íŒŒì‹±
        close_parsed = parse_json_array('close_d', 3)
        df['close_today'] = close_parsed[0]
        df['close_yesterday'] = close_parsed[1]
        df['close_2ago'] = close_parsed[2]

        # MA20 íŒŒì‹±
        ma20_parsed = parse_json_array('ma20', 3)
        df['ma20_today'] = ma20_parsed[0]
        df['ma20_yesterday'] = ma20_parsed[1]
        df['ma20_2ago'] = ma20_parsed[2]

        # MA50 íŒŒì‹±
        ma50_parsed = parse_json_array('ma50', 3)
        df['ma50_today'] = ma50_parsed[0]
        df['ma50_yesterday'] = ma50_parsed[1]
        df['ma50_2ago'] = ma50_parsed[2]

        # MA200 íŒŒì‹±
        ma200_parsed = parse_json_array('ma200', 3)
        df['ma200_today'] = ma200_parsed[0]
        df['ma200_yesterday'] = ma200_parsed[1]
        df['ma200_2ago'] = ma200_parsed[2]

        if 'per' not in df.columns:
            df['per'] = 0.0
        if 'eps' not in df.columns:
            df['eps'] = 0.0
        if 'sector' not in df.columns:
            df['sector'] = 'N/A'
        if 'sector_trend' not in df.columns:
            df['sector_trend'] = 'N/A'

        market_filter = df['market'].isin(
            ['US'] if use_us and not use_kr else
            ['KR'] if use_kr and not use_us else
            ['US', 'KR']
        )
        df_filtered = df[market_filter].copy()

        # ì˜ì—…ì¼ ì¡°ì •
        today = datetime.now()
        if today.weekday() >= 5:
            days_back = today.weekday() - 4
            today -= timedelta(days=days_back)
        today_str = today.strftime('%Y-%m-%d')

        save_columns = ['symbol', 'market', 'name', 'rsi_d', 'macd_d', 'signal_d', 'obv_d', 
                       'signal_obv_9d', 'signal_obv_20d', 'market_cap', 'avg_trading_value_20d', 
                       'today_trading_value', 'turnover', 'per', 'eps', 'cap_status', 
                       'upper_closes', 'lower_closes', 'sector', 'sector_trend',
                       'ma20', 'ma50', 'ma200', 'break_20high', 'close_d', 'close']

        # ========================================
        # âœ… ë‹¨ê¸° ìŠ¤í¬ë¦¬ë‹
        # ========================================
        print("\në‹¨ê¸° ìŠ¤í¬ë¦¬ë‹ ì‹œì‘...")
        short_conditions = (
            # OBV ìƒìŠ¹ í¬ë¡œìŠ¤
            (df_filtered['obv_latest'] > df_filtered['signal_obv_9_latest']) &
            (df_filtered['obv_1ago'] <= df_filtered['signal_obv_9_1ago']) &
            # ê±°ë˜ëŒ€ê¸ˆ ê¸‰ì¦
            (df_filtered['today_trading_value'] >= 2.0 * df_filtered['avg_trading_value_20d']) &
            # ëŒíŒŒ
            ((df_filtered['break_20high'] == 1) | 
             ((df_filtered['close_today'] > df_filtered['ma20_today']) & 
              (df_filtered['close_yesterday'] <= df_filtered['ma20_yesterday'])))
        )

        short_results = df_filtered[short_conditions].copy()
        short_results = add_close_price(short_results)

        if not short_results.empty:
            short_results = short_results.sort_values('market_cap', ascending=False).head(top_n)
            short_results_save = short_results[save_columns].copy()
            short_file = os.path.join(SHORT_FOLDER, f'{today_str}_short.csv')
            short_results_save.to_csv(short_file, index=False, encoding='utf-8-sig')
            print(f"âœ… ë‹¨ê¸° ê²°ê³¼: {len(short_results)}ê°œ â†’ {short_file}")
        else:
            print("âš ï¸ ë‹¨ê¸° ì¡°ê±´ ë§Œì¡± ì¢…ëª© ì—†ìŒ")

        # ========================================
        # âœ… ì¤‘ê¸° ìŠ¤í¬ë¦¬ë‹
        # ========================================
        print("\nì¤‘ê¸° ìŠ¤í¬ë¦¬ë‹ ì‹œì‘...")
        mid_conditions = (
            # RSI ìƒìŠ¹ (40~60)
            (df_filtered['rsi_d_2ago'] < df_filtered['rsi_d_1ago']) &
            (df_filtered['rsi_d_1ago'] < df_filtered['rsi_d_latest']) &
            (df_filtered['rsi_d_latest'] >= 40) &
            (df_filtered['rsi_d_latest'] <= 60) &
            # OBV ìš°ìƒí–¥/í¬ë¡œìŠ¤
            (df_filtered['obv_latest'] > df_filtered['signal_obv_20_latest']) &
            (
                (df_filtered['signal_obv_20_latest'] > df_filtered['signal_obv_20_3ago']) |
                ((df_filtered['obv_2ago'] <= df_filtered['signal_obv_20_2ago']) & 
                 (df_filtered['obv_latest'] > df_filtered['signal_obv_20_latest'])) |
                ((df_filtered['obv_1ago'] <= df_filtered['signal_obv_20_1ago']) & 
                 (df_filtered['obv_latest'] > df_filtered['signal_obv_20_latest']))
            ) &
            # ê³¨ë“ í¬ë¡œìŠ¤
            (df_filtered['ma50_today'] > df_filtered['ma200_today']) &
            # ê±°ë˜ëŒ€ê¸ˆ
            (df_filtered['today_trading_value'] >= df_filtered['avg_trading_value_20d'])
        )

        mid_results = df_filtered[mid_conditions].copy()
        mid_results = add_close_price(mid_results)

        if not mid_results.empty:
            mid_results = mid_results.sort_values('market_cap', ascending=False).head(top_n)
            mid_results_save = mid_results[save_columns].copy()
            mid_file = os.path.join(MID_FOLDER, f'{today_str}_mid.csv')
            mid_results_save.to_csv(mid_file, index=False, encoding='utf-8-sig')
            print(f"âœ… ì¤‘ê¸° ê²°ê³¼: {len(mid_results)}ê°œ â†’ {mid_file}")
        else:
            print("âš ï¸ ì¤‘ê¸° ì¡°ê±´ ë§Œì¡± ì¢…ëª© ì—†ìŒ")

        # ========================================
        # âœ… ë§¤ë„ ìŠ¤í¬ë¦¬ë‹
        # ========================================
        print("\në§¤ë„ ìŠ¤í¬ë¦¬ë‹ ì‹œì‘...")
        sell_conditions = (
            # RSI ê³¼ì—´
            (df_filtered['rsi_d_latest'] >= 70) |
            # OBV í•˜ë½ í¬ë¡œìŠ¤
            ((df_filtered['obv_latest'] < df_filtered['signal_obv_9_latest']) &
             (df_filtered['obv_1ago'] >= df_filtered['signal_obv_9_1ago'])) |
            # RSI í•˜ê°•
            ((df_filtered['rsi_d_2ago'] > df_filtered['rsi_d_1ago']) &
             (df_filtered['rsi_d_1ago'] > df_filtered['rsi_d_latest']) &
             (df_filtered['rsi_d_latest'] <= 50))
        )

        sell_results = df_filtered[sell_conditions].copy()
        sell_results = add_close_price(sell_results)

        if not sell_results.empty:
            sell_results = sell_results.sort_values('market_cap', ascending=False).head(top_n)
            sell_results_save = sell_results[save_columns].copy()
            sell_file = os.path.join(SELL_FOLDER, f'{today_str}_sell_signals.csv')
            sell_results_save.to_csv(sell_file, index=False, encoding='utf-8-sig')
            print(f"âœ… ë§¤ë„ ê²°ê³¼: {len(sell_results)}ê°œ â†’ {sell_file}")
        else:
            print("âš ï¸ ë§¤ë„ ì¡°ê±´ ë§Œì¡± ì¢…ëª© ì—†ìŒ")

        # ë°±í…ŒìŠ¤íŒ… DB ìƒì„±
        create_backtest_db()

        # âœ… í…ŒìŠ¤íŠ¸ íƒ­ìš© ë°ì´í„° ìƒì„±
        create_backtest_test()

        return pd.DataFrame()

    except Exception as e:
        print(f"ìŠ¤í¬ë¦¬ë„ˆ ì—ëŸ¬: {e}")
        traceback.print_exc()
        return pd.DataFrame()

def load_all_csv_from_folder(folder_path, result_type):
    all_df = pd.DataFrame()
    if not os.path.exists(folder_path):
        return all_df
    for file in os.listdir(folder_path):
        if file.endswith('.csv'):
            file_path = os.path.join(folder_path, file)
            df = pd.read_csv(file_path, dtype={'symbol': str})
            df['type'] = result_type
            
            # âœ… í•œêµ­ ì¢…ëª© symbolì„ 6ìë¦¬ë¡œ í†µì¼
            if len(df) > 0 and 'market' in df.columns:
                kr_mask = df['market'] == 'KR'
                if kr_mask.any():
                    df.loc[kr_mask, 'symbol'] = df.loc[kr_mask, 'symbol'].str.zfill(6)
            
            all_df = pd.concat([all_df, df], ignore_index=True)
    return all_df

def create_backtest_db():
    print("\n" + "="*60)
    print("ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ DB ìƒì„± ì¤‘...")
    print("="*60)
    
    short_df = load_all_csv_from_folder(SHORT_FOLDER, 'short')
    mid_df = load_all_csv_from_folder(MID_FOLDER, 'mid')

    print(f"\nğŸ“ ë¡œë“œëœ ë°ì´í„°:")
    print(f"   - ë‹¨ê¸° CSV: {len(short_df)}í–‰")
    print(f"   - ì¤‘ê¸° CSV: {len(mid_df)}í–‰")

    all_df = pd.concat([short_df, mid_df], ignore_index=True)
    
    if not all_df.empty and 'market' in all_df.columns and 'symbol' in all_df.columns:
        all_df['symbol'] = all_df['symbol'].astype(str)
        kr_mask = all_df['market'] == 'KR'
        all_df.loc[kr_mask, 'symbol'] = all_df.loc[kr_mask, 'symbol'].str.zfill(6)
        print(f"   âœ… í•œêµ­ ì¢…ëª© symbol í˜•ì‹ í†µì¼ ì™„ë£Œ")
    
    if all_df.empty:
        print("âš ï¸ ë°±í…ŒìŠ¤íŠ¸í•  ë°ì´í„° ì—†ìŒ")
        return
    
    print(f"   - ì „ì²´: {len(all_df)}í–‰")
    
    # ê¸°ì¡´ ì™„ë£Œ ë°ì´í„° ë¡œë“œ (ì¤‘ë³µ ì²´í¬ìš©)
    completed_csv_path = os.path.join(DATA_DIR, 'backtest_completed.csv')
    existing_completed_set = set()

    if os.path.exists(completed_csv_path):
        try:
            existing_completed = pd.read_csv(completed_csv_path, dtype={'symbol': str})
            
            kr_mask = existing_completed['market'] == 'KR'
            existing_completed.loc[kr_mask, 'symbol'] = existing_completed.loc[kr_mask, 'symbol'].str.zfill(6)
            
            for _, row in existing_completed.iterrows():
                key = f"{str(row['symbol'])}_{str(row['market'])}_{str(row['type'])}_{str(row['base_date'])}"
                existing_completed_set.add(key)
            
            print(f"\nğŸ“‚ ê¸°ì¡´ ì™„ë£Œ ë°ì´í„°: {len(existing_completed)}ê°œ")
            print(f"   (ê³ ìœ  í‚¤: {len(existing_completed_set)}ê°œ)")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ì™„ë£Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print(f"\nğŸ“‚ ê¸°ì¡´ ì™„ë£Œ ë°ì´í„°: ì—†ìŒ (ì‹ ê·œ ìƒì„±)")
    
    print(f"\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„° (ì²« 3í–‰):")
    for i, row in all_df.head(3).iterrows():
        print(f"   [{i}] {row.get('symbol', 'N/A')} | {row.get('market', 'N/A')} | cap_status: {row.get('cap_status', 'N/A')} | type: {row.get('type', 'N/A')}")
    
    meta = load_meta()
    today = datetime.now()
    print(f"\nğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ: {today.strftime('%Y-%m-%d')}")
    
    pending_list = []
    completed_list = []
    skip_count = 0
    already_completed_count = 0
    
    for idx, row in all_df.iterrows():
        symbol = row['symbol']
        market = row['market']
        result_type = row['type']
        
        # 1. ê¸°ì¤€ì¼ íŒŒì‹±
        base_date_str = row.get('cap_status', 'N/A')
        
        try:
            base_date = datetime.strptime(base_date_str, '%Y-%m-%d')
        except Exception as e:
            print(f"âš ï¸ [{idx}] ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {symbol} ({market}) - cap_status: '{base_date_str}' - ì—ëŸ¬: {e}")
            skip_count += 1
            continue
        
        # 2. ëª©í‘œì¼ ê³„ì‚°
        if result_type == 'short':
            target_date = base_date + timedelta(days=30)
        elif result_type == 'mid':
            target_date = base_date + timedelta(days=90)
        else:
            print(f"âš ï¸ [{idx}] ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…: {symbol} ({market}) - type: '{result_type}'")
            skip_count += 1
            continue
        
        # 3. ì™„ë£Œ ì—¬ë¶€ í™•ì¸
        days_elapsed = (today - base_date).days
        is_completed = today >= target_date
        
        # 4. symbol_key ìƒì„±
        if market == 'KR':
            symbol_key = str(symbol).zfill(6)
        else:
            symbol_key = str(symbol)
        
        check_key = f"{symbol_key}_{market}_{result_type}_{base_date_str}"

        if is_completed and check_key in existing_completed_set:
            already_completed_count += 1
            if already_completed_count <= 5:
                print(f"â­ï¸ [{idx}] {symbol_key} ({market}) {result_type} {base_date_str} - ì´ë¯¸ ì™„ë£Œë¨, ìŠ¤í‚µ")
            continue
        
        if idx < 5:
            print(f"\nğŸ” [{idx}] {symbol_key} ({market}) - {result_type}")
            print(f"    ê¸°ì¤€ì¼: {base_date.strftime('%Y-%m-%d')}")
            print(f"    ëª©í‘œì¼: {target_date.strftime('%Y-%m-%d')} ({'+30ì¼' if result_type == 'short' else '+90ì¼'})")
            print(f"    ê²½ê³¼ì¼: {days_elapsed}ì¼")
            print(f"    ì™„ë£Œì—¬ë¶€: {'âœ… ì™„ë£Œ' if is_completed else 'â³ ëŒ€ê¸° ì¤‘'}")
        
        # 5. ë©”íƒ€ ë° ê¸°ì¤€ì¼ ì¢…ê°€
        meta_dict = meta.get(market, {}).get(symbol_key, {})
        base_close = row.get('close', 0.0)
        
        if is_completed:
            target_close = get_historical_close(symbol_key, market, target_date)
            
            if target_close is None:
                print(f"âš ï¸ [{idx}] {symbol_key} - CSVì— ëª©í‘œì¼({target_date.strftime('%Y-%m-%d')}) ë°ì´í„° ì—†ìŒ")
                print(f"    â†’ í˜„ì¬ ì¢…ê°€ë¡œ ëŒ€ì²´ (ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ)")
                target_close = meta_dict.get('close', 0.0)
                
                if target_close == 0.0:
                    print(f"    â†’ ë©”íƒ€ì—ë„ ì¢…ê°€ ì—†ìŒ, ëŒ€ê¸° ì¤‘ìœ¼ë¡œ ìœ ì§€")
                    is_completed = False
            
            if is_completed:
                current_close = target_close
                current_update = target_date.strftime('%Y-%m-%d')
                
                if idx < 5:
                    print(f"    ëª©í‘œì¼ ì¢…ê°€: {current_close:,.0f}")
        
        if not is_completed:
            current_close = meta_dict.get('close', 0.0)
            current_update = meta_dict.get('cap_status', 'N/A')
        
        # 6. ë°ì´í„° êµ¬ì„±
        record = {
            'symbol': symbol_key,
            'market': market,
            'name': row.get('name', 'N/A'),
            'sector': row.get('sector', 'N/A'),
            'sector_trend': row.get('sector_trend', 'N/A'),
            'type': result_type,
            'base_date': base_date_str,
            'target_date': target_date.strftime('%Y-%m-%d'),
            'days_elapsed': days_elapsed,
            'close': base_close,
            'market_cap': row.get('market_cap', 0.0),
            'avg_trading_value_20d': row.get('avg_trading_value_20d', 0.0),
            'today_trading_value': row.get('today_trading_value', 0.0),
            'turnover': row.get('turnover', 0.0),
            'per': row.get('per', 0.0),
            'eps': row.get('eps', 0.0),
            'cap_status': base_date_str,
            'upper_closes': row.get('upper_closes', 0),
            'lower_closes': row.get('lower_closes', 0),
            'rsi_d': row.get('rsi_d', '[]'),
            'macd_d': row.get('macd_d', '[]'),
            'signal_d': row.get('signal_d', '[]'),
            'obv_d': row.get('obv_d', '[]'),
            'signal_obv_9d': row.get('signal_obv_9d', '[]'),
            'signal_obv_20d': row.get('signal_obv_20d', '[]'),
            'ma20': row.get('ma20', '[]'),
            'ma50': row.get('ma50', '[]'),
            'ma200': row.get('ma200', '[]'),
            'break_20high': row.get('break_20high', 0),
            'close_d': row.get('close_d', '[]'),
        }
        
        # 7. ì™„ë£Œ ì—¬ë¶€ì— ë”°ë¼ ë¶„ë¥˜
        if is_completed:
            record['latest_close'] = current_close
            record['latest_update'] = current_update
            change_rate = ((current_close - base_close) / base_close * 100) if base_close != 0 else 0.0
            record['change_rate'] = round(change_rate, 2)
            completed_list.append(record)
        else:
            record['latest_close'] = current_close
            record['latest_update'] = current_update
            change_rate = ((current_close - base_close) / base_close * 100) if base_close != 0 else 0.0
            record['change_rate'] = round(change_rate, 2)
            pending_list.append(record)
    
    # 8. ë°ì´í„°í”„ë ˆì„ ìƒì„±
    pending_df = pd.DataFrame(pending_list)
    completed_df = pd.DataFrame(completed_list)
    
    print(f"\n" + "="*60)
    print(f"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼:")
    print(f"   - ìŠ¤í‚µë¨ (íŒŒì‹± ì‹¤íŒ¨): {skip_count}ê°œ")
    print(f"   - ì´ë¯¸ ì™„ë£Œë¨ (ì¤‘ë³µ ìŠ¤í‚µ): {already_completed_count}ê°œ")
    print(f"   - ëŒ€ê¸° ì¤‘: {len(pending_df)}ê°œ")
    print(f"   - ì‹ ê·œ ì™„ë£Œ: {len(completed_df)}ê°œ")
    print("="*60)
    
    # 9. DB ë° CSV ì €ì¥
    if not pending_df.empty:
        con_back = duckdb.connect(BACKTEST_DB_PATH)
        con_back.execute("DROP TABLE IF EXISTS backtest")
        con_back.execute("CREATE TABLE backtest AS SELECT * FROM pending_df")
        con_back.close()
        
        pending_df.to_csv(BACKTEST_CSV_PATH, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ë°±í…ŒìŠ¤íŠ¸ ëŒ€ê¸° ì¤‘: {len(pending_df)}ê°œ ì¢…ëª©")
        print(f"   ğŸ“„ {BACKTEST_CSV_PATH}")
    else:
        print("\nâš ï¸ ëŒ€ê¸° ì¤‘ì¸ ë°±í…ŒìŠ¤íŠ¸ ì¢…ëª© ì—†ìŒ")
    
    if not completed_df.empty:
        if os.path.exists(completed_csv_path):
            existing_completed = pd.read_csv(completed_csv_path, dtype={'symbol': str})
            
            kr_mask = existing_completed['market'] == 'KR'
            existing_completed.loc[kr_mask, 'symbol'] = existing_completed.loc[kr_mask, 'symbol'].str.zfill(6)
            
            combined = pd.concat([existing_completed, completed_df], ignore_index=True)
            combined = combined.drop_duplicates(subset=['symbol', 'market', 'type', 'base_date'], keep='last')
            combined.to_csv(completed_csv_path, index=False, encoding='utf-8-sig', quoting=1)
            
            print(f"\nâœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(completed_df)}ê°œ ì¢…ëª© ì¶”ê°€ (ì´ {len(combined)}ê°œ)")
            print(f"   (ê¸°ì¡´ {len(existing_completed)}ê°œ + ì‹ ê·œ {len(completed_df)}ê°œ = ë³‘í•© í›„ {len(combined)}ê°œ)")
            print(f"   ğŸ“„ {completed_csv_path}")
        else:
            completed_df.to_csv(completed_csv_path, index=False, encoding='utf-8-sig', quoting=1)
            
            print(f"\nâœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(completed_df)}ê°œ ì¢…ëª© (ì‹ ê·œ)")
            print(f"   ğŸ“„ {completed_csv_path}")
    
    # 10. í†µê³„ ì¶œë ¥
    print(f"\n" + "="*60)
    print(f"ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½")
    print(f"   - ëŒ€ê¸° ì¤‘: {len(pending_df)}ê°œ")
    if not pending_df.empty:
        print(f"     Â· ë‹¨ê¸°(1ê°œì›”): {len(pending_df[pending_df['type'] == 'short'])}ê°œ")
        print(f"     Â· ì¤‘ê¸°(3ê°œì›”): {len(pending_df[pending_df['type'] == 'mid'])}ê°œ")
    print(f"   - ì‹ ê·œ ì™„ë£Œ: {len(completed_df)}ê°œ")
    if not completed_df.empty:
        print(f"     Â· ë‹¨ê¸°(1ê°œì›”): {len(completed_df[completed_df['type'] == 'short'])}ê°œ")
        print(f"     Â· ì¤‘ê¸°(3ê°œì›”): {len(completed_df[completed_df['type'] == 'mid'])}ê°œ")
        avg_return = completed_df['change_rate'].mean()
        win_rate = (completed_df['change_rate'] > 0).sum() / len(completed_df) * 100
        print(f"   - í‰ê·  ìˆ˜ìµë¥ : {avg_return:.2f}%")
        print(f"   - ìŠ¹ë¥ : {win_rate:.1f}%")
    
    if os.path.exists(completed_csv_path):
        all_completed = pd.read_csv(completed_csv_path, dtype={'symbol': str})
        print(f"\n   ğŸ“Š ì „ì²´ ì™„ë£Œ í†µê³„ (ëˆ„ì ):")
        print(f"     Â· ì´ ì™„ë£Œ: {len(all_completed)}ê°œ")
        print(f"     Â· ë‹¨ê¸°(1ê°œì›”): {len(all_completed[all_completed['type'] == 'short'])}ê°œ")
        print(f"     Â· ì¤‘ê¸°(3ê°œì›”): {len(all_completed[all_completed['type'] == 'mid'])}ê°œ")
        if len(all_completed) > 0:
            all_avg_return = all_completed['change_rate'].mean()
            all_win_rate = (all_completed['change_rate'] > 0).sum() / len(all_completed) * 100
            print(f"     Â· í‰ê·  ìˆ˜ìµë¥ : {all_avg_return:.2f}%")
            print(f"     Â· ìŠ¹ë¥ : {all_win_rate:.1f}%")
    
    print("="*60 + "\n")


def create_backtest_test():
    """
    í…ŒìŠ¤íŠ¸ íƒ­ìš© ë°ì´í„° ìƒì„± â†’ backtest_test.csv
    ê¸°ì¤€ì¼ë¡œë¶€í„° +5%, +10% ì²« ë‹¬ì„±ì¼ê³¼ ìµœì¢…ì¼ ì¢…ê°€ë¥¼ ê¸°ë¡
    - ë¯¸ë‹¬ì„±: ë¹ˆì¹¸
    - ì™„ë£Œ(ë‹¨ê¸° 1ê°œì›” / ì¤‘ê¸° 3ê°œì›” ê²½ê³¼): final_close, final_change_rate ê¸°ë¡
    """
    print("\n" + "="*60)
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ íƒ­ ë°ì´í„° ìƒì„± ì¤‘ (backtest_test.csv)...")
    print("="*60)

    short_df = load_all_csv_from_folder(SHORT_FOLDER, 'short')
    mid_df = load_all_csv_from_folder(MID_FOLDER, 'mid')
    all_df = pd.concat([short_df, mid_df], ignore_index=True)

    if not all_df.empty and 'market' in all_df.columns and 'symbol' in all_df.columns:
        all_df['symbol'] = all_df['symbol'].astype(str)
        kr_mask = all_df['market'] == 'KR'
        all_df.loc[kr_mask, 'symbol'] = all_df.loc[kr_mask, 'symbol'].str.zfill(6)

    if all_df.empty:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ íƒ­ ìƒì„±í•  ë°ì´í„° ì—†ìŒ")
        return

    print(f"   - ì „ì²´ ì…ë ¥: {len(all_df)}í–‰")

    # âœ… ê¸°ì¡´ backtest_test.csv ë¡œë“œ (ì¤‘ë³µ ì²´í¬ìš©)
    existing_test_set = set()
    existing_test_df = pd.DataFrame()

    if os.path.exists(BACKTEST_TEST_CSV_PATH):
        try:
            existing_test_df = pd.read_csv(BACKTEST_TEST_CSV_PATH, dtype={'symbol': str})
            kr_mask = existing_test_df['market'] == 'KR'
            existing_test_df.loc[kr_mask, 'symbol'] = existing_test_df.loc[kr_mask, 'symbol'].str.zfill(6)
            for _, row in existing_test_df.iterrows():
                key = f"{str(row['symbol'])}_{str(row['market'])}_{str(row['type'])}_{str(row['base_date'])}"
                existing_test_set.add(key)
            print(f"   - ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(existing_test_df)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print(f"   - ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì—†ìŒ (ì‹ ê·œ ìƒì„±)")

    today = datetime.now()
    new_records = []
    update_keys = []  # ì™„ë£Œ ì „í™˜ëœ í•­ëª© key ëª©ë¡ (ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ìš©)
    skip_count = 0

    for idx, row in all_df.iterrows():
        symbol = row['symbol']
        market = row['market']
        result_type = row['type']

        # 1. ê¸°ì¤€ì¼ íŒŒì‹±
        base_date_str = row.get('cap_status', 'N/A')
        try:
            base_date = datetime.strptime(base_date_str, '%Y-%m-%d')
        except Exception as e:
            print(f"âš ï¸ [{idx}] ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {symbol} ({market}) - '{base_date_str}' - {e}")
            skip_count += 1
            continue

        # 2. ëª©í‘œì¼ ê³„ì‚°
        if result_type == 'short':
            target_date = base_date + timedelta(days=30)
        elif result_type == 'mid':
            target_date = base_date + timedelta(days=90)
        else:
            skip_count += 1
            continue

        # 3. symbol_key í†µì¼
        if market == 'KR':
            symbol_key = str(symbol).zfill(6)
        else:
            symbol_key = str(symbol)

        check_key = f"{symbol_key}_{market}_{result_type}_{base_date_str}"
        is_completed = today >= target_date

        # âœ… ì´ë¯¸ ì™„ë£Œ ì²˜ë¦¬ëœ í•­ëª©ì€ ìŠ¤í‚µ
        if check_key in existing_test_set:
            # ì™„ë£Œ ì „í™˜ ì²´í¬: ê¸°ì¡´ì— is_completed=0ì¸ë° ì§€ê¸ˆì€ ì™„ë£Œëìœ¼ë©´ ì—…ë°ì´íŠ¸ í•„ìš”
            if is_completed and not existing_test_df.empty:
                existing_row = existing_test_df[
                    (existing_test_df['symbol'] == symbol_key) &
                    (existing_test_df['market'] == market) &
                    (existing_test_df['type'] == result_type) &
                    (existing_test_df['base_date'] == base_date_str)
                ]
                if not existing_row.empty:
                    # ì´ë¯¸ is_completed=1ì´ë©´ ì™„ì „ ìŠ¤í‚µ
                    if int(existing_row.iloc[0].get('is_completed', 0)) == 1:
                        continue
                    # is_completed=0ì´ì—ˆë‹¤ë©´ â†’ ì•„ë˜ì—ì„œ ì¬ê³„ì‚° (ìŠ¤í‚µ ì•ˆ í•¨)
                    else:
                        update_keys.append(check_key)
                else:
                    continue
            else:
                continue

        # 4. ê¸°ì¤€ê°€
        base_close = float(row.get('close', 0.0))
        if base_close == 0.0:
            skip_count += 1
            continue

        # 5. ê¸°ì¤€ì¼ ì´í›„ ì¼ë³„ ì¢…ê°€ ì¡°íšŒ
        df_range = get_closes_in_range(symbol_key, market, base_date, target_date)

        # 6. +5%, +10% ë‹¬ì„±ì¼ íƒìƒ‰
        date_5pct = ''
        date_10pct = ''
        price_5pct = base_close * 1.05
        price_10pct = base_close * 1.10

        for _, price_row in df_range.iterrows():
            close_val = float(price_row['close'])
            date_val = str(price_row['date'])
            if date_5pct == '' and close_val >= price_5pct:
                date_5pct = date_val
            if date_10pct == '' and close_val >= price_10pct:
                date_10pct = date_val
            # ë‘˜ ë‹¤ ì°¾ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
            if date_5pct != '' and date_10pct != '':
                break

        # 7. ìµœì¢…ì¼ ì¢…ê°€ (ì™„ë£Œëœ ê²½ìš°ë§Œ)
        final_close = ''
        final_change_rate = ''

        if is_completed:
            fc = get_historical_close(symbol_key, market, target_date)
            if fc is not None and fc != 0.0:
                final_close = fc
                final_change_rate = round(((fc - base_close) / base_close) * 100, 2)

        # 8. ë ˆì½”ë“œ êµ¬ì„±
        record = {
            'symbol': symbol_key,
            'market': market,
            'name': row.get('name', 'N/A'),
            'sector': row.get('sector', 'N/A'),
            'type': result_type,
            'base_date': base_date_str,
            'target_date': target_date.strftime('%Y-%m-%d'),
            'base_close': base_close,
            'date_5pct': date_5pct,
            'date_10pct': date_10pct,
            'final_close': final_close,
            'final_change_rate': final_change_rate,
            'is_completed': 1 if is_completed and final_close != '' else 0,
        }
        new_records.append(record)

    # 9. ê¸°ì¡´ ë°ì´í„° + ì‹ ê·œ ë°ì´í„° ë³‘í•© ì €ì¥
    new_df = pd.DataFrame(new_records)

    if not new_df.empty or not existing_test_df.empty:
        # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ì—…ë°ì´íŠ¸ ëŒ€ìƒ ì œê±° í›„ ì‹ ê·œ ì¶”ê°€
        if not existing_test_df.empty and update_keys:
            existing_test_df['_key'] = (
                existing_test_df['symbol'].astype(str) + '_' +
                existing_test_df['market'].astype(str) + '_' +
                existing_test_df['type'].astype(str) + '_' +
                existing_test_df['base_date'].astype(str)
            )
            existing_test_df = existing_test_df[~existing_test_df['_key'].isin(update_keys)]
            existing_test_df = existing_test_df.drop(columns=['_key'])

        combined = pd.concat([existing_test_df, new_df], ignore_index=True)
        combined = combined.drop_duplicates(
            subset=['symbol', 'market', 'type', 'base_date'], keep='last'
        )
        combined.to_csv(BACKTEST_TEST_CSV_PATH, index=False, encoding='utf-8-sig', quoting=1)
        print(f"\nâœ… í…ŒìŠ¤íŠ¸ íƒ­ ì €ì¥ ì™„ë£Œ: {len(combined)}ê°œ ì¢…ëª©")
        print(f"   - ì‹ ê·œ/ì—…ë°ì´íŠ¸: {len(new_df)}ê°œ")
        print(f"   - ì™„ë£Œë¨: {len(combined[combined['is_completed'] == 1])}ê°œ")
        print(f"   - ëŒ€ê¸° ì¤‘: {len(combined[combined['is_completed'] == 0])}ê°œ")
        print(f"   ğŸ“„ {BACKTEST_TEST_CSV_PATH}")

        # ê°„ë‹¨ í†µê³„
        done = combined[combined['is_completed'] == 1].copy()
        if len(done) > 0:
            done['final_change_rate'] = pd.to_numeric(done['final_change_rate'], errors='coerce')
            avg_r = done['final_change_rate'].mean()
            win_r = (done['final_change_rate'] > 0).sum() / len(done) * 100
            cnt_5 = (done['date_5pct'] != '').sum()
            cnt_10 = (done['date_10pct'] != '').sum()
            print(f"\n   ğŸ“Š ì™„ë£Œ í†µê³„:")
            print(f"     Â· í‰ê·  ìˆ˜ìµë¥ : {avg_r:.2f}%")
            print(f"     Â· ìŠ¹ë¥ : {win_r:.1f}%")
            print(f"     Â· +5% ë‹¬ì„±: {cnt_5}ê°œ ({cnt_5/len(done)*100:.1f}%)")
            print(f"     Â· +10% ë‹¬ì„±: {cnt_10}ê°œ ({cnt_10/len(done)*100:.1f}%)")
    else:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ íƒ­ ì €ì¥í•  ë°ì´í„° ì—†ìŒ")

    if skip_count > 0:
        print(f"   - ìŠ¤í‚µë¨: {skip_count}ê°œ")

    print("="*60 + "\n")


if __name__ == "__main__":
    use_us = sys.argv[1].lower() == 'true' if len(sys.argv) > 1 else True
    use_kr = sys.argv[2].lower() == 'true' if len(sys.argv) > 2 else True
    top_n = int(sys.argv[3]) if len(sys.argv) > 3 else 50

    print(f"ìŠ¤í¬ë¦¬ë„ˆ ì‹¤í–‰ â†’ US: {use_us}, KR: {use_kr}, Top {top_n}ê°œ")
    results = run_screener(top_n, use_us, use_kr)
    
    if con:
        con.close()
    print("\nğŸ‰ ìŠ¤í¬ë¦¬ë„ˆ ì¢…ë£Œ!")